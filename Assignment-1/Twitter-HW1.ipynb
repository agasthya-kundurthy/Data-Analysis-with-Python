{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Sentiment Analysis of Tweets\n",
    "A simple Sentiment Analysis is to performed to understand the data obtained(tweets) from twitter based on a trending topic.\n",
    "\n",
    "Many people use Twitter as a platform to share and comment on their views about any topic. So, twitter is chosen to gather data.\n",
    "\n",
    "The trending topic chosen here is 'snowday' as snowfall has started in many places all over the world due to the start of winter. \n",
    "\n",
    "## Accomplished Tasks:\n",
    "* Worked with and configured access to a Twitter API.\n",
    "* Identified a trending topic on Twitter - 'snowday'.\n",
    "* Lists of stop words, positive words, and negative words were obtained from Github.\n",
    "* A ratio of the positive and negative words has been arrived at to understand the data.\n",
    "\n",
    "## Questions Answered:\n",
    "* What is the ratio of positive to negative words on your trending topic?\n",
    "* What is your interpretation of the ratio?\n",
    "* What is the managerial insight that you could offer based on your results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach taken to arrive at the solution\n",
    "\n",
    "* A Twitter API was used to obtain data from Twitter by writing the code in a config file and running it in the terminal. This code consists of Consumer and Access Keys available via the Twitter Developer platform to connect and get data from Twitter.\n",
    "\n",
    "* The file is run and the output JSON of the file is stored in a text file. Then, the text file loaded is read, the content is stored as a list of words. These words are compared with an existing list sets of positive, negative and stop words.\n",
    "\n",
    "* Two integers maintain the occurrences of positive and negative words, a ratio is arrived at based on these counts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To generate multiple outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data generated is a JSON format, and so it needs to be read and the tweets are stored in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the sample-data text file which has the contents and store the tweets data(JSON format) into a list.\n",
    "tweets_data = []\n",
    "f = open('sample-data.txt', 'r')\n",
    "for line in f:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "        \n",
    "    except:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the 'text' of the tweets from JSON format!\n",
    "tweetsData = []\n",
    "for a in tweets_data:\n",
    "    if('text' in a):\n",
    "        text = a['text']\n",
    "        tweetsData.append(text)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of Negative words from the negative-words text file and put it in a list!\n",
    "negative_words = []\n",
    "file = open('negative-words.txt', 'r')\n",
    "for word in file:\n",
    "    word = word.strip()\n",
    "    negative_words.append(word)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of Positive words from the positive-words text file and put it in a list!\n",
    "positive_words = []\n",
    "file = open('positive-words.txt', 'r')\n",
    "for word in file:\n",
    "    word = word.strip()\n",
    "    positive_words.append(word)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the list of stop words from the stopwords text file and put it in a list!\n",
    "stopwords = []\n",
    "file = open('stopwords.txt', 'r')\n",
    "for word in file:\n",
    "    word = word.strip()\n",
    "    stopwords.append(word)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Positive Words -  12944\n",
      "Total Negative Words -  10722\n",
      "Ratio of Positive to Negative words is -  1.2072374556985637\n"
     ]
    }
   ],
   "source": [
    "#Tweets are in the form of sentences, so break them down to words and store them in a list to compare with positive,negative or stop words.\n",
    "\n",
    "tweetsFinal = []\n",
    "for w in tweetsData:\n",
    "    for word in w.split():\n",
    "        tweetsFinal.append(word)\n",
    "        \n",
    "#Set the initial count of positive and Negative variables to Zero.\n",
    "\n",
    "count_positive = 0\n",
    "count_negative = 0\n",
    "countTotal = 0\n",
    "\n",
    "#Go through the tweets and find the list of words matching and increment the count of positive and negative words respectively.\n",
    "\n",
    "for word in tweetsFinal:\n",
    "    countTotal = countTotal+1\n",
    "    if word in stopwords:\n",
    "        continue\n",
    "    elif word in positive_words:\n",
    "         count_positive = count_positive + 1\n",
    "    elif word in negative_words:\n",
    "         count_negative = count_negative + 1\n",
    "            \n",
    "print('Total Positive Words - ',count_positive)\n",
    "print('Total Negative Words - ',count_negative)   \n",
    "ratio = count_positive/count_negative\n",
    "print('Ratio of Positive to Negative words is - ', ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "\n",
    "The ratio that we are getting shows that overall there is a positive feel towards the start of snowfall all over the world. The positive feel could be attributed to the fact that people tend to enjoy when there is a light snow fall. The climate is welcoming and people generally are attracted towards rain and snow. It makes them want to experience a warm and cozy feel in their homes. Whether it is children or adults, both generally have the tendency to play with the snow and enjoy. And who wouldn't want to enjoy a hot cup of coffee on a cold morning!\n",
    "\n",
    "People like snowfall for different reasons, Although the positive feel is on the higher side, the Negative feel is also considerably high maybe because of higher snowfall in certain places and snowfall impacting the daily life of people living at those places, higher snowfall could mean that people can't go outside of their homes due to unbearable conditions and possible frost bites. And change of weather in places generally comes with the higher risks of flu spreading in a region. \n",
    "\n",
    "Further Analysis on a bigger Dataset and using a sentiment Analysis tool could be more helpful to arrive at better insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Roadmap\n",
    "\n",
    "#### Use of APIs\n",
    "The sentiment Analysis done here does not use any APIs that are available for free use. If these APIs were used, the prediction of sentiment towards a topic could be even better. It would be interesting to see the workings of such APIs and using them would dramatically decrease the run time of the program. Use of multiple for loops could be avoided.\n",
    "\n",
    "#### Bigger Data set and region wise comparison, better Insights!\n",
    "Also, the data taken here is of small size, a bigger data set would be required to perform a better sentiment analysis of the data. A country or state wise graph could be possible based on a larger dataset, this would help us compare the sentiments of tweets from a particular region and a clearer relationship could be formed with the temperature of the region in consideration which could lead to having better insights and probably a different ratio than the current ratio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "* ### Data\n",
    "\n",
    "     Negative words - https://gist.github.com/mkulakowski2/4289441\n",
    "\n",
    "     Positive Words - https://gist.github.com/mkulakowski2/4289437\n",
    "\n",
    "     Stop words - https://kb.yoast.com/kb/list-stop-words/\n",
    "     \n",
    "\n",
    "* ### API Code\n",
    "\n",
    "      http://adilmoujahid.com/posts/2014/07/twitter-analytics/\n",
    "\n",
    "* ### Trending Topics\n",
    "\n",
    "      https://trends24.in/united-states/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
